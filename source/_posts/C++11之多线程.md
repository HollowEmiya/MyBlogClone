---
title: C++11 多线程
date: 2023-08-21 20:24:22
tags: 
typora-root-url: ./..
---
  
[小彭老师](https://www.bilibili.com/video/BV1Ya411q7y4/?spm_id_from=333.1007.top_right_bar_window_history.content.click&vd_source=1fa1b82383f6efb8a2632316da9afad0)
  
之前一直没有系统学过，最近心里也很乱，听一下小彭老师然后自己整理了一些。
  
<!--more-->
  
# Multithreading
  
## Time
  
### C++11 标准库：`std::chrono`
  
* 利用 C++ 强类型的特点，明确 **时间点** 和 **时间段**，区分不同的**时间单位**。
  
* 时间点：2023年8月22日 21点38分54秒
  
* 时间段：2分20秒
  
* 时间点类型：`chrono::steady_clock::time_pointer` 等
  
* 时间段类型：`chrono::milliseconds`, `chrono::seconds`, `chrono::minutes` 等等。  
  ~~~C++  
  auto t0 = chrono::stready_clock::now();		// 当前时间点  
  auto t1 = t0 + chrono::seconds(30);			// 当前时间30s后  
  auto dt = t1 - t0;		// 两个时间点的差，时间段  
  int64_t sec = chrono::duration_cast<chrono::seconds>(dt).count();			// 获取时间差的秒数  
  double ms = std::chrono::duration_cast<std::chrono::duration<double, std::million>>(dt).count();  
  ~~~
  
  std::chrono::duration<T, R> , 用 T 类型表示，单位为 R，单位不写默认为秒。  
  std::chrono::second 是 std::chrono::duration<int_64> 的类型别名
  
#### 跨平台 sleep：`std::this_thread::sleep_for`
  
~~~C++
std::this_thread::sleep_for(std::chrono::milliseconds(480));
~~~
  
* milliseconds 毫秒  
* microseconds 微秒  
* seconds
  
#### `std::this_thread::sleep_until`
  
睡到某个时间点  
~~~c++
auto t = std::chrono::steady_clock::now() + std::chrono::milliseconds(400);
std::this_thread::sleep_until(t);
~~~
  
## Thread
  
* **进程**：我们的一个程序就是一个进程  
* **线程**：线程是进程中的实体，是系统调度、分配的最小单位。  
  进程本身不能获取 CPU 时间，而线程可以。  
* 每个线程共享内存空间，开销较小。  
* 每个进程拥有独立的内存空间，因此开销更大。
  
#### 为什么需要多线程
  
可以实现无阻塞的多任务程序。  
做到程序的异步实现。
  
* 比如：下载器，下载一个大文件的同时还需要和用户进行交互。  
  这个时候下载文件 和 用户交互就是一个进程的两个任务。  
  如果不使用线程，纯串行，在下载时用户就无法操作了，只能等待下载完毕。  
* 不用多进程是因为，进程的地址独立，进程间沟通困难，消耗资源更多。
  
### C++ 多线程：`std::thread`
  
* `std::thread` 构造函数的参数可以是任意的 lambda 表达式。  
* 当线程启动，就会指向 lambda 里的内容。
  
#### 错误：找不到符号 `pthread_thread`
  
这是因为 `std::thread` 是基于 `pthread`的，  
所以在 CMakeLists.txt 里链接 Threads::Threads 即可。
  
~~~cmake
cmake_minimum_required(VERSION 3.10)

set(CMAKE_CXX_STANDARD 17)

project(threadDemo LANGUAGES CXX)

add_executable(threadDemo main.cpp)

find_package(Threads REQUIRED)
target_link_libraries(threadDemo PUBLIC Threads::Threads)
~~~
  
就是这两行：  
`find_package(Threads REQUIRED)`  
`target_link_libraries(threadDemo PUBLIC Threads::Threads)`
  
### 主线程等待子线程
  
在我们退出主线程时，可能子线程还未执行完毕。  
可以使用 std::thread 类的 join() 来等待某一个进程的结束。  
我们可以使用 joinable() 判断 thread 对象是否还对线程有管理权限。
  
### std::thread 的解构函数会销毁线程
  
* 作为 C++ 类同样遵循 RAII 思想，线程实际也是一种资源。  
  thread 自定义了解构函数，删除了拷贝构造函数、拷贝赋值函数，但提供了移动构造函数、移动复制函数。
  
### 析构函数不再销毁线程：t1.detach()
  
调用成员函数 detach() 可以将线程和 std::thread 对象分离。  
意味着 线程 的生命周期不再由当前 std::thread 对象管理，而在线程退出以后自动销毁自己。  
不过这也还是会在进程结束后，自动退出，因为进程结束会调用 terminal 销毁全部线程。
  
### 析构函数不再销毁线程：自己构建全局线程池
  
如果不想，detach 后线程还未执行完毕就销毁。  
可以自己建一个全局的线程池，创建线程就 push 进去，在程序结束前 逐个 join 即可。
  
~~~c++
std::vector<std::thread> poll;

void func()
{
    std::thread t1([&]{
        download("hello.zip");
    });
    pool.push_back(std::move(t1));
}

int main()
{
    func();
   
    for(auto &th : pool) th.join();
}
~~~
  
#### 改进一下
  
~~~C++
class ThreadPool
{
    std::vector<std::thread> m_pool;
    
public:
    void push_back(std::thread thr)
    {
        m_pool.push_back(std::move(thr));
    }
    
    ~ThreadPool()
    {
        for(auto &t : m_pool) t.join();
    }
};

ThreadPool tpool;

void func()
{
    std::thread t1([&]{
        download();
    });
    tpool.push_back(std::move(t1));
}

int main()
{
    func();
    return 0;
}
~~~
  
### C++20 引入 `std::jthread`：符合 RAII 思想，解构时自动 join()
  
* C++ 20 的 `std::jthread` 和 `std::thread` 的不同在于，其解构函数会自动调用 join() 函数，让线程等待，直到完全执行。
  
## 碎碎念
  
python 没有线程，其实是 并发而非并行。  
blender 也用了 怕python 而且 ui 层由OpenGL渲染出来，所以很多都是单线程会出现等待不能操作的结果。
  
OpenGL 和 DX12相比就是，DX12 是支持多线程的可以做到真正的并发，计算性能会提升很多。
  
## 异步
  
### `std::async`
  
~~~C++
int download()
{
    // do something a long time
    return 404;
}

void interact()
{
    std::string name;
    std::cin >> name;
    std::cout << "Hi, " << name << std::endl;
}

int main()
{
    std::future<int> fret = std::async([&]{
        return download();
    });
    interact();
    int ret = fret.get();
    std::cout << "Result is:" << ret << std::endl;
    return 0;
}
~~~
  
* `std::async` 接受一个带有返回值的 lambda，自身返回一个 `std::future` 对象。  
  这个 future 是什么意思呢？在 `std::future<int> fret=..` 这里 fret 的返回值是 `int`，意思就是这个 int 现在还没有，但是我保证以后一定会有。   
* 这 `async` 里的 lambda 并非立即执行，而是在后台会挂起一个线程默默执行。  
* 最后调用 future 的 **get()** 方法，如果此时 download 还没完成，会**等待** download 完成，并获取 返回值。
  
#### 等待 wait
  
* 除了 get()，future 还有 **wait()** ，可以等待执行结束但是不会返回其值。
  
#### 等待一段时间：wait_for()
  
* 线程未结束，wait() 会无限等待。  
* 而 wait_for() 则可以指定一个最长的等待时间，用 chrono 里的类表示单位。他会返回一个 std::future_status 表示等待是否完成。  
* 如果超过时间还未完成，就会放弃等待，返回 `future_status::timeout`  
* 如果线程在指定时间内执行完毕，等待就成功了，返回`future_status::ready`  
* 同理还有 `wait_until()` 其参数是一个时间点。
  
#### 另一种用法：`std::launch::deferred` 做 `std::async` 的参数
  
* `std::async` 的第一个参数可设为 `std:;launch::deferred`，这时不会创建线程，只会把 lambda 函数体内的运算**推迟**到 future 的 get() 被调用后。  
* 这种写法，lambda 的执行仍在主线程中，只是函数式编程上的异步，而不涉及到多线程。(可以用这个实现惰性求值(lazy evaluation) )
  
~~~c++
std::future<int> fret = std::async(std::launch::deferred, [&]{
    return 909;
});
~~~
  
### `std::async` 的底层实现：`std::promise`
  
~~~C++
int main()
{
    std::promise<int> pret;
    std::thread t1([&]{
        auto ret = download();
        pret.set_value(ret);
    });
    std:::funture<int> fret = pret.get_future();
    
}
~~~
  
* 如果不想 `std::async` 帮你自动创建线程，想要手动创建线程，可以直接用 `std::promise`  
* 然后线程返回时，用 `set_value()` 设置返回值。  
  在主线程中，用 `get_future()` 获取其 `std::future`对象，进一步 `get()` 可以等待并获取线程返回值。
  
### std::future 小贴士
  
* 为了符合 RAII 思想，删除了拷贝构造函数和拷贝赋值函数。  
  如果需要浅拷贝，实现共享同一个 future 对象，可以使用 `std：：shared_future`。  
* 如果不需要返回值，`std::async` 里的 lambda 返回类型可以为 void，但这时的 future 对象也要为 `std::future<void>`  
* 同理有 `std::promise<void>`，但其 set_value() 不接受参数，仅仅作为同步作用，没有实际的值。
  
## 互斥量
  
### 多线程打架实例
  
~~~c++
int main()
{
    std::vector<int> arr;
    std::thread t1([&]{
        for(int i = 0; i < 1000; ++i)
        {
            arr.push_back(1);
        }
    });
    std::thread t2([&]{
        for(int i = 0; i < 1000; ++i)
        {
            arr.push_back(2);
        }
    });
    t1.join();
    t2.join();
    return 0;
}
~~~
  
* 两个线程向同一个数组里推数据导致崩溃。  
* vector 并非 多线程安全 (MT-safe) 的容器。  
  多个线程同时访问同一个 vector 对象会出现 **数据竞争 (data-race) **现象。
  
### `std::mutex` ：上锁，防止多个线程进入某一段代码
  
* 调用 `std::mutex` 的 `lock()` 时，会检测 `mutex` 是否已经**上锁**。  
* 如果没有**锁定**，则对 `mutex` 进行上锁  
* 如果已经**锁定**，则陷入等待，直到 `mutex` 被另一线程**解锁**后，才再次**上锁**。  
* 调用 `unlock()` 则会解锁操作  
* 这样可以保证 lock 和 unlock 之间的代码段，同一时间只有一个线程在执行，避免数据竞争。
  
### `std::lock_guard`: 符合 RAII 思想的锁
  
* 根据 RAII 思想，锁视为一种资源，上锁视为锁的获取，解锁视为锁的释放。  
* `std::lock_guard` 就是这样的一个工具类，其构造函数会 `mtx.lock()`，解构函数会 `mtx.unlock()`。从而退出函数作用域时能够自动解锁，避免程序员忘记解锁。
  
~~~C++
int main()
{
    std::vector<int> arr;
    std::mutex mtx;
    std::thread t1([&]{
        std::lock_guard grd(mtx);
        arr.push_back(1);
    });
    
    std::thread t2([&]{
        std::lock_guard grd(mtx);
        arr.push_back(2);
    });
    
    t1.join();
    t2.join();
    return 0;
}
~~~
  
但是也因为 `lock_guard`太符合 RAII 思想，导致其很死板，我们想提前 unlock 只能让他超出其作用范围。  
为了更灵活的应用锁，就有了 `unique_lock` 
  
### `std::unique_lock`: 符合 RAII 思想，但自由度更高
  
* `std::lock_guard` 严格在解构时 unlock()，但我们有时希望提前 unlock。这时就可以使用 `std::unique_lock`，他额外存储了一个 flag 表示释放已经被释放。他会在解构时检测这个 flag，如果没有释放，则调用 unlock，否则不调用。  
* 然后可以直接调用 unique_lock 的 unlock 函数来提前解锁，但即使忘记也没关系，在超出作用域时其会自动检测一边是否需要解锁。
  
#### `std::unique_lock`: 用 `std::defer_lock` 作为参数
  
* `std::unique_lock` 的构造函数还可以有一个额外参数 `std::defer_lock`  
* 指定此参数后，`std::unique_lock`不会在构造函数中 `mtx.lock()`了，需要后续手动 `grd.lock()` 才能上锁。  
* 好处是，即使忘记了 `grd.unlock()` 也能够自动调用 `mtx.unlock()`
  
~~~C++
int main()
{
    std::vector<int> arr;
    std::mutex mtx;
    std::thread t1([&]{
        for(int i=0;i<10;i++)
        {
            std::unique_lock<std::mutex> grd(mtx);
            arr.push_back(1);
		}
    });
    
    
    std::thread t2([&]{
        for(int i=0;i<10;i++)
        {
            std::unique_lock<std::mutex>grd(mtx, std::defer_lock);
            grd.lock();
            arr.push_back(2);
            // grd.unlock();
		}
    });
    
    t1.join();
    t2.join();
    return;
}
~~~
  
### 多个对象？每个对象使用一个 mutex 即可
  
~~~c++
int main()
{
    std::vector<int> arr1;
    std::vector<int> arr2;
    
    std::mutex mtx1;
    std::mutex mtx2;
    
    std::thread t1([&]{
        for(int i = 0; i < 10; i++)
        {
            {
                std::lock_guard grd(mtx1);
            	arr1.push_back(1);
            }
            
            {
                std::lock_guard grd(mtx2);
                arr2.push_back(1);
            }
        }
    });
    
    std::thread t2([&]{
        for(int i = 0; i < 10; i++)
        {
            {
                std::lock_guard grd(mtx1);
            	arr1.push_back(2);
            }
            
            {
                std::lock_guard grd(mtx2);
                arr2.push_back(2);
            }
        }
    });
    
    t1.join();
    t2.join();
    return;
}
~~~
  
### 如果上锁失败，却不想等待：`try_lock()`
  
~~~c++
int main()
{
    std::mutex mtx1;
    if(mtx1.try_lock())
    {
        std::cout << "Successed!" << std::endl;
    }
    else
    {
        std::cout << "Failed!" << std::endl;
    }
    
    if(mtx1.try_lock())
    {
        std::cout << "Successed!" << std::endl;
    }
    else
    {
        std::cout << "Failed!" << std::endl;
    }
    
    mtx.unlock();
    return;
}
~~~
  
* `lock()` 如果发现 `mutex` 已经上锁的话，会等待他直到他解锁。  
* 如果使用 `try_lock()` ，其上锁失败不会阻塞，而是直接返回 false，上锁成功会返回 true。
  
### `try_lock_for`
  
~~~C++
int main()
{
    std::mutex mtx1;
    if(mtx1.try_lock_for(std::chrono::milliseconds(500)))
    {
        std::cout << "Successed!" << std::endl;
    }
    else
    {
        std::cout << "Failed!" << std::endl;
    }
    
    if(mtx1.try_lock_for(std::chrono::milliseconds(500)))
    {
        std::cout << "Successed!" << std::endl;
    }
    else
    {
        std::cout << "Failed!" << std::endl;
    }
    
    mtx.unlock();
    return;
}
~~~
  
* 在 `try_lock()` 的基础上，但是会等待一段时间。  
* 类似的还有 `try_lock_until()`
  
### `std::unique_lock`: 用 `std::try_to_lock` 做参数
  
* 和无参数相比，它会调用 `mtx.try_lock()` 而非 `mtx.lock()`.  
  `grd.owns_lock()` 判断是否上锁成功。
  
  ~~~c++  
  int main()  
  {  
      std::mutex mtx;  
      std::thread t1([&]{  
          std::unique_lock<std::mutex>grd(mtx, std::try_to_lock);  
          if(grd.owns_lock())  
          {  
              std::cout << "Successed!" << std::endl;  
          }  
          else  
          {  
              std::cout << "Failed!" << std::endl;  
              std::this_thread::sleep_for(std::chrono::milliseconds(1000));  
          }  
      });
      
      t1.jion();  
      t2.join();
      
      return 0;  
  }  
  ~~~
  
### `std::unique_lock`: `std::adopt_lock` 做参数
  
~~~c++
int main()
{
    std::mutex mtx;
    std::thread t1([&]{
        std::unique_lock<std::mutex>grd(mtx);
        std::cout << "t1 lock the mutex" << std::endl;
        std::this_thread::sleep_for(std:chrono::milliseconds(1000));
    });
    
    std::thread t2([&]{
        mtx.lock();
        std::unique_lock<std::mutex>grd(mtx, std::adopt_lock);
        std::cout << "t2 lock the mutex" << std::endl;
        std::this_thread::sleep_for(std:chrono::milliseconds(1000));
    });
	t1.jion();
    t2.join();
    
    return 0;
}
~~~
  
* 作用就是当我们的 mutex 已经上锁，但是我们又想使用 unique_lock / lock_guard 这种符合 RAII 思想的封装，以实现其可以自我解构，我们就在构造时使用 std::adopt_lock，就默认这个 mutex 已经上锁了。
  
### `std::unique_lock` 和 `std::mutex` 有相同的接口
  
* `std::unique_lock` 拥有 `std::mutex` 的所有成员函数：`lock()`, `unlock()`, `try_lock()`, `try_lock_for()` 等等。  
  只是 unique_lock 会自动调用 unlock 罢了  
* 而 `std::lock_guard` 无非是调用其构造参数中 名为 lock() 的成员函数罢了，所有我们甚至可以用 `std::unique_lock` 做 `std::lock_guard` 的构造函数参数 
  
* 更进一步，只要我们能有 满足 mutex 类对于成员函数的类，就可以做为 `std::lock_guard` 构造函数的参数。  
  这种只要具有某些指定名字的成员函数，就可以判断一个类是否满足某些功能的思想，被成为 concept(概念)，相比 虚函数 和 动态多态的接口抽象，concept 能够使实现更加解耦，并且不会有性能损失。
  
## 死锁
  
### 同时锁住多个 mutex
  
~~~c++
int main()
{
    std::mutex mtx1;
    std::mutex mtx2;
    
    std:thread t1([&]{
        for(int i = 0; i < 1000; ++i)
        {
            mtx1.lock();
            mtx2.lock();
            mtx2.unlock();
            mtx1.unlock();
        }
    });
    
    std:thread t2([&]{
        for(int i = 0; i < 1000; ++i)
        {
            mtx2.lock();
            mtx1.lock();
            mtx1.unlock();
            mtx2.unlock();
        }
    });
    
    t1.jion();
    t2.join();
    
    return 0;
}
~~~
  
* 因为线程是同步进行的，所以其指令不一定是同步的  
* 可能就会：  
  * t1锁住了mtx1  
  * t2锁住了mtx2  
  * t1需要锁mtx2，但是t2锁住了mtx2  
  * t2需要锁mtx1，但是t1锁住了mtx1  
  * t1，t2都陷入无尽的等待
  
#### 解决1：永远不要同时持有两个锁
  
* 简单粗暴的就是<u>不让一个线程同时持有两个锁</u>，分别上锁，来避免死锁
  
~~~c++
int main()
{
    std::mutex mtx1;
    std::mutex mtx2;
    
    std::thread t1([&]{
        for(int i = 0; i < 100; i++)
        {
            mtx1.lock();
            mtx1.unlock();
            mtx2.lock();
            mtx2.unlock();
        }
    });
    
    std::thread t2([&]{
        for(int i = 0; i < 100; i++)
        {
            mtx2.lock();
            mtx2.unlock();
            mtx1.lock();
            mtx1.unlock();
        }
    });
    
    t1.jion();
    t2.join();
    
    return 0;
}
~~~
  
#### 解决方案2：确保双方上锁顺序一致
  
* 前面死锁是因为两个线程上锁的顺序不同，<u>保证双方上锁的顺序一致，即可避免死锁</u>
  
~~~C++
int main()
{
    std::mutex mtx1;
    std::mutex mtx2;
    
    std::thread t1([&]{
        for(int i = 0; i < 100; i++)
        {
            mtx1.lock();
            mtx2.lock();
            mtx1.unlock();
            mtx2.unlock();
        }
    });
    
    std::thread t2([&]{
        for(int i = 0; i < 100; i++)
        {
            mtx1.lock();
            mtx2.lock();
            mtx2.unlock();
            mtx1.unlock();
        }
    });
    
    t1.jion();
    t2.join();
    
    return 0;
}
~~~
  
#### 解决方案3：使用 `std::lock` 同时对多个 mutex 上锁
  
* `std::lock`  接受任意个 mutex 作为参数，且保证 <u>无论任意线程中调用的顺序是否相同，都不会产生死锁问题</u>
  
~~~C++
int main()
{
    std::mutex mtx1;
    std::mutex mtx2;
    
    std::thread t1([&]{
        for(int i = 0; i < 1000; i++)
        {
			std::lock(mtx1, mtx2);
            mtx1.unlock();
            mtx2.unlock();
        }
    });
    
    std::thread t2([&]{
        for(int i = 0; i < 1000; i++)
        {
            std::lock(mtx2, mtx1);
            mtx2.unlock();
            mtx1.unlock();
        }
    });
    
    t1.join();
    t2.join();
    return 0;
}
~~~
  
#### `std::lock` 的 RAII 版本 : `std::scoped_lock`
  
* 和 `std::lock_guard` / `std::unique_lock`相对应，`std::lock` 也有 RAII 的版本 `std::scoped_lock`, 只不过其可以同时对多个 mutex 上锁。
  
### 同一个线程重复调用 lock() 也会造成死锁
  
~~~C++
std::mutex mtx;

void other()
{
	mtx.lock();
    //...
    mtx.unlock();
}

void func()
{
	mtx.lock();
    other();
    mtx.unlock();
}

int main()
{
    func();
    return 0;
}
~~~
  
* 这里 `func` lock了mtx，而lock之后调用 other，other 需要 mtx，陷入等待  
  这就是 同一线程多次对同一个 mutex 进行 lock 导致死锁。
  
#### 解决一：other 不 lock
  
这种情况一定要说明 other 非线程安全的，在调用前务必保证其 mutex 已经上锁。
  
#### 解决二：改用 `std::recursive_mutex`
  
~~~C++
std::recursive_mutex mtx;

void other()
{
	mtx.lock();
    //...
    mtx.unlock();
}

void func()
{
	mtx.lock();
    other();
    mtx.unlock();
}

int main()
{
    func();
    return 0;
}
~~~
  
* 如果 `other` 不让改，可以用 `std::recursive_mutex`  
  会判断是不是同一个线程 `lock()` 了多次同一个锁  
  如果是则让计数器加1，在之后 `unlock()` 时会让计数器减1，减到0时才真正解锁。但是相比普通的 `std::mutex` 会有一定的性能损失。
  
* 也有 `std::recursive_timed_mutex`，如果我们需要 `try_lock_for()`
  
## 数据结构
  
### 案例：多线程使用 `std::vector`
  
之前提到 `vector` 是线程不安全的，会出现数据竞争(data-race)
  
### 封装线程安全的 `vector`
  
加入我们这样做：  
~~~C++
class MTVector
{
    std::mutex m_mutex;
    std::vector<int> m_arr;
    
public:
    void push_back(val)
    {
        m_mtx.lock();
        m_arr.push_back(val);
        m_mtr.unlock();
    }
    
    size_t size() const
    {
        m_mtx.lock();	//
        size_t ret = m_arr.size();
        m_mtx.unlock();	//
        return ret;
    }
};
~~~
  
* 我们用用一个类进行简单封装，使访问都受到 `mutex` 的保护  
* 但是会出错哦，因为 `size()` 是 `const` 函数，而 `mutex::lock()` 并非 `const` 函数。但是 `size()`为了兼容之前的代码，必须是 const 的。
  
#### 逻辑上 `const` 而部分成员非 `const`: `mutable`
  
* 我们必须为了 `mutex` 放弃声明 `size()` 为 `const` 吗？  
  不必这样，`size()` 在逻辑上仍然应该是 `const` 的。  
  所以，为了能让 `this` 为 `const` 时仅仅对 `m_mtx` 做特殊处理，可以声明 `mutable` 关键字修饰他，从而所有成员只有他不是 `const` 的。
  
~~~C++
class MTVector
{
    mutable std::mutex m_mutex;	//
    std::vector<int> m_arr;
    
public:
    void push_back(val)
    {
        m_mtx.lock();
        m_arr.push_back(val);
        m_mtr.unlock();
    }
    
    size_t size() const
    {
        m_mtx.lock();
        size_t ret = m_arr.size();
        m_mtx.unlock();
        return ret;
    }
};
~~~
  
### 为什么需要读写锁
  
实际上我们**读的时候可以共享**，但是写的时候不能共享，**写必须独占**，因为写一半被读取可能会读到错误的数据。
  
所以就有了读写锁，读写情况有三种：
  
* n 个人读，没有写入  
* 1 个人写入，没有读取  
* 没有读取，也没有写入
  
### `shared_mutex` —— 读写锁
  
~~~c++
class MTVector
{
    mutable std::shared_mutex m_mutex;	//
    std::vector<int> m_arr;
    
public:
    void push_back(val)
    {
        m_mtx.lock();
        m_arr.push_back(val);
        m_mtr.unlock();
    }
    
    size_t size() const
    {
        m_mtx.lock_shared();
        size_t ret = m_arr.size();
        m_mtx.unlock_shared();
        return ret;
    }
};
~~~
  
* 在上锁时，指定需求是 **读** 或者 **写**，负责调度的读写锁会帮助我们 判断是否需要等待。  
* `push_back` 是写，所以使用 `lock` 和 `unlock`  
* `size` 是读，使用 `lock_shared` 和 `unlock_shared`
  
### `std::shared_lock` : 符合 RAII 思想的 `lock_shared()`
  
* 我们用 `std::unique_lock` 封装 `lock()` 和 `unlock()`  
  对应的，`std::shared_lock` 封装了 `lock_shared()` 和 `unlock_shared()`  
* `shared_lock` 也支持 `defer_lock` 做参数，`owns_lock()` 判断等等。
  
~~~C++
class MTVector
{
    mutable std::shared_mutex m_mutex;	//
    std::vector<int> m_arr;
    
public:
    void push_back(val)
    {
        std::unique_lock<std::shared_mutex>grd(m_mtx);	// 注意这里是 unique_lock
        m_arr.push_back(val);
    }
    
    size_t size() const
    {
        std::shared_lock grd(m_mtx);	// 注意这里是 shared_lock
        size_t ret = m_arr.size();
        return ret;
    }
};
~~~
  
### 只需一次性上锁，且符合 RAII 思想：访问者模式
  
~~~c++
class MTVector
{
    std::vector<int> m_arr;
    std::mutex m_mtx;
    
public:
    class Accessor
    {
    	MTVector &m_that;
        std::unique_lock<std::mutex> m_guard;
        
    public:
        Accessor(MTVector &that)
            : m_that(that), m_guard(that.m_mtx)
        {
        
        }
        
        void push_back(int val) const
        {
            return m_that.m_arr.push_back(val);
        }
        
        size_t size() const
        {
            return m_that.m_arr.size();
        }
    };
    
    Accessor access()
    {
        return {*this};
    }
};
~~~
  
* Accessor access() 将 `MTVector` 的 `this` 指针作为 Access 构造函数的参数  
* 因为多次上锁解锁是存在性能消耗的
  
如果使用 shared_mutex  
~~~C++
class MTVector
{
    std::vector<int> m_arr;
    std::shared_mutex m_mtx;
    
public:
    class Accessor
    {
    	MTVector &m_that;
        std::unique_lock<std::shared_mutex> m_guard;
        
    public:
        Accessor(MTVector &that)
            : m_that(that), m_guard(that.m_mtx)
        {
        
        }
        
        void push_back(int val) const
        {
            return m_that.m_arr.push_back(val);
        }
    };
    
    class ConstAccessor
    {
    	MTVector &m_that;
        std::shared_lock<std::shared_mutex> m_guard;
        
    public:
        Accessor(MTVector &that)
            : m_that(that), m_guard(that.m_mtx)
        {
        
        }
        
        size_t size() const
        {
            return m_that.m_arr.size();
        }
    };
    
    Accessor access()
    {
        return {*this};
    }
    
    ConstAccessor const_access()
    {
        return {*this};
    }
};
~~~
  
## 条件变量
  
之前的互斥量更多的是防止数据竞争  
而条件变量就类似他的名字，更多的是一个条件，只有条件发生了，这个线程才会继续执行。
  
### 条件变量：等待被唤醒
  
~~~C++
int main()
{
    std::condition_variable cv;
    std:;mutex mtx;
    
    std::thread t1([&]{
        std::unique_lock<std::mutex>lck(mtx);
        cv.wait(lck);
        
        std::cout << "T1 is awake." << std::endl;
    });
    
    std::this_thread::sleep_for(std::chrono::millionseconds(400));
    
    std::cout << "Notifying ..." << std::endl;
    cv.notify_one();
    
    t1.join();
    return 0;
}
~~~
  
* `cv.wait(lck)` 将会让当前线程陷入等待。  
* 在其他线程中调用 `cv.notify_one()` 则会唤醒那个陷入等待的线程。  
* `std::condition_variable` 必须和 `std:unique_lock<std::mutex>` 一起使用
  
### 条件变量：等待某一变量成真
  
~~~c++
int main()
{
    std::condition_variable cv;
    std::mutex mtx;
    bool ready = false;
    
    std::thread t1([&]{
        std::unique_lock<std::mutex> lck(mtx);
        cv.wait(lck, [&] { return ready});
        lck.unlock();
        
        std::cout << "T1 is awake." << std::endl;
    });
    
    std::cout << "Notifying not ready!" << std::endl;
    cv.notify_one();
    
        
    ready = true;
    std::cout << "Notifying ready" << std::endl;
    cv.notify_one();
    
    t1.join();
    return 0;
}
~~~
  
* `cv.wait(lck, expr)` 中 `expr` 是一个 lambda 表达式。  
  只有返回值为 true 时才会被唤醒，否则继续等待。
  
### 条件变量：多个等待者
  
~~~C++
int main()
{
    std::condition_variable cv;
    std::mutex mtx;
    
    std::thread t1([&] {
        std::unique_lock<std::mutex> lck(mtx);
        cv.wait(lck);
        std::cout << "T1 is awake!" << std::endl;
    });
    
    std::condition_variable cv;
    std::mutex mtx;
    
    std::thread t2([&] {
        std::unique_lock<std::mutex> lck(mtx);
        cv.wait(lck);
        std::cout << "T2 is awake!" << std::endl;
    });
    
    std::condition_variable cv;
    std::mutex mtx;
    
    std::thread t3([&] {
        std::unique_lock<std::mutex> lck(mtx);
        cv.wait(lck);
        std::cout << "T3 is awake!" << std::endl;
    });
    
    std::this_thread::sleep_for(std::chrono::millionseconds(400));
    
    std::cout << "Notify One" << std::endl;
    cv.notify_one();	// awake t1 only
    
    std::this_thread::sleep_for(std::chrono::millionseconds(400));
    
    std::cout << "Notify One" << std::endl;
    cv.notify_all();	// awake t2 and t3
    
    t1.join();
    t2.join();
    t3.join();
}
~~~
  
* `cv.notify_one()` 只会唤醒其中一个等待的线程，而 `cv.notify_all()` 会唤醒全部。  
* 这就是为什么 `wait()` 需要有个 `unique_lock` 作为参数，因为要保证多个线程同时唤醒时只有一个可以被启动。如果不需要这个锁，在 `wait()` 返回后调用 `lck.unlock()` 即可。  
* `wait()` 的过程中会暂时 `unlock()` 这个锁。
  
### 实例：实现生产者-消费者模式
  
~~~c++
int main()
{
    std::condition_variable cv;
    std::mutex mtx;
    
    std::vector<int> foods;
    
    std::thread t1([&] {
        std::unique_lock<std::mutex> lck(mtx);
        
        cv.wait(lck, [&]{
            return foods.size() != 0;
        });
        
        auto food = foods.back();
        foods.pop_back();
        lck.unlock();
        
        std::cout << "T1 get food: " << food << std::endl;
    });
    
    
    std::thread t2([&] {
        std::unique_lock<std::mutex> lck(mtx);
        
        cv.wait(lck, [&]{
            return foods.size() != 0;
        });
        
        auto food = foods.back();
        foods.pop_back();
        lck.unlock();
        
        std::cout << "T2 get food: " << food << std::endl;
    });
    
    foods.push_back(42);
    cv.notify_one();
    foods.push_back(422);
    cv.notify_one();
    
    foods.push_back(66);
    foods.push_back(92);
    cv.notify_all();
    
    t1.join();
    t2.join();
    
    return 0;
}
~~~
  
### `std::condition_variable` tips
  
1. `std::condition_variable` 仅支持 `std::unique_lock<std::mutex>` 作为参数，如果需要其他类型的 mutex，使用 `std::condition_variable_any`  
2. 其还有 `wait_for()` 和 `wait_until()` 分别接受 chrono 的时间段和时间点
  
## 原子操作
  
### 经典案例：多个线程修改同一个计数器
  
~~~c++
int main()
{
    int counter = 0;
    
    std::thread t1([&] {
        for(int i=0;i<100;i++)
        {
            counter += 1;
        }
    });
    
    std::thread t2([&] {
        for(int i=0;i<100;i++)
        {
            counter += 1;
        }
    });
    
    t1.join();
    t2.join();
    std::cout << counter<< std::endl;
    return 0;
}
~~~
  
这里即便是简单的 +1 操作也会冲突，因为对于 CPU 而言会是多个指令，执行时会发生冲突。
  
如果我们的操作不是原子的，就会造成数据冲入或者写入/读取错误。
  
#### 暴力解决：mutex 上锁
  
* 能解决，但是这样操作系统来进行线程调度，会进入**内核态**再回到用户态，这样切换，有很大的开销。  
* 归根结底就是 mutex 太昂贵了
  
#### 建议使用 atomic：有专门的硬件指令加持
  
~~~C++
int main()
{
    std::atomic<int> counter = 0;
    
    std::thread t1([&] {
        for(int i=0;i<100;i++)
        {
            counter += 1;
        }
    });
    
    std::thread t2([&] {
        for(int i=0;i<100;i++)
        {
            counter += 1;
        }
    });
    
    t1.join();
    t2.join();
    std::cout << counter<< std::endl;
    return 0;
}
~~~
  
* atomic 对 += 等操作会转换为专门的指令  
* CPU 识别到对应的指令会锁住内存总线，放弃乱序执行的优化，强制同步之前的内存操作，保证操作的原子性。  
* 注意，对 += 和 ++ 原子，但是分开写 c = c + 1 就不可以了
  
### fetch_add：和 += 等价 
  
* `fetch_add` : +=  
* `store ` : =  
* `load` 读取 `int` 值
  
### fetch_add 能够返回旧值
  
* 先 fetch 一个旧值，然后再 add  
* 这个特点使其可以**并行地往一个列表追加数据**
  
### exchange：读取的同时写入
  
先取出来，然后再写入
  
### compare_exchange_strong
  
读取，比较是否相等，相等则写入
  
`counter.compare_exchange_strong(cmp,val)` counter 和 cmp 比，相等就写入val值  